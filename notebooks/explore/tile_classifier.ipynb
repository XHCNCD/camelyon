{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating classifier for tiles\n",
    "* Based off: Deep Learning for Identifying Metastatic Breast Cancer arXiv:1606.05718v1\n",
    "\n",
    "Differences:\n",
    "* Use inception v3 (not google lenet)\n",
    "* how many samples did they generate?\n",
    "\n",
    "Transfer Learning code from:\n",
    "http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Directory where data is stored\n",
    "data_dir = '/media/rene/Data/camelyon_out/tiles_299_1t'\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 1\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=num_workers)\n",
    "              for x in ['train', 'valid']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception model is weird\n",
    "* Input may be normalized differently than other imagenet models\n",
    "* The output is a tuple consisting of: (actual ouput, aux loss)\n",
    "* To train full model must sum this aux loss\n",
    "* Making prediction is different if in training phase or not. In training must look at 1st variable in tuple, in validation you just have normal output.\n",
    "\n",
    "Info:\n",
    "https://github.com/ahirner/pytorch-retraining/blob/master/retrain_benchmark_bees.ipynb\n",
    "https://discuss.pytorch.org/t/imagenet-example-with-inception-v3/1691/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # for nets that have multiple outputs such as inception\n",
    "                if isinstance(outputs, tuple):\n",
    "                    loss = sum((criterion(o,labels) for o in outputs))\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    _, preds = torch.max(outputs[0].data, 1)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(dataloaders['valid']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "            imshow(inputs.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=was_training)\n",
    "                return\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.inception_v3(pretrained=True)\n",
    "\n",
    "# for p in model_ft.parameters():\n",
    "#     p.requires_grad=False\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.8403 Acc: 0.7495\n",
      "valid Loss: 0.1999 Acc: 0.9286\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5357 Acc: 0.8772\n",
      "valid Loss: 0.2768 Acc: 0.8750\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4050 Acc: 0.9159\n",
      "valid Loss: 0.2036 Acc: 0.8929\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3901 Acc: 0.9226\n",
      "valid Loss: 0.1108 Acc: 0.9286\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3204 Acc: 0.9323\n",
      "valid Loss: 0.2298 Acc: 0.9107\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2871 Acc: 0.9449\n",
      "valid Loss: 0.1679 Acc: 0.9107\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2267 Acc: 0.9545\n",
      "valid Loss: 0.2981 Acc: 0.8750\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1765 Acc: 0.9691\n",
      "valid Loss: 0.2279 Acc: 0.9107\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2006 Acc: 0.9584\n",
      "valid Loss: 0.2177 Acc: 0.9107\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1309 Acc: 0.9778\n",
      "valid Loss: 0.2577 Acc: 0.9107\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1305 Acc: 0.9739\n",
      "valid Loss: 0.2019 Acc: 0.9107\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9797\n",
      "valid Loss: 0.3141 Acc: 0.9107\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1209 Acc: 0.9768\n",
      "valid Loss: 0.2140 Acc: 0.9107\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1210 Acc: 0.9807\n",
      "valid Loss: 0.2980 Acc: 0.9107\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1284 Acc: 0.9797\n",
      "valid Loss: 0.3049 Acc: 0.9107\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1184 Acc: 0.9826\n",
      "valid Loss: 0.3391 Acc: 0.9107\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0960 Acc: 0.9865\n",
      "valid Loss: 0.2800 Acc: 0.9107\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1300 Acc: 0.9778\n",
      "valid Loss: 0.2886 Acc: 0.9107\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1040 Acc: 0.9845\n",
      "valid Loss: 0.2424 Acc: 0.9107\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9845\n",
      "valid Loss: 0.2256 Acc: 0.9107\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1314 Acc: 0.9758\n",
      "valid Loss: 0.2853 Acc: 0.9107\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9884\n",
      "valid Loss: 0.2659 Acc: 0.9107\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9807\n",
      "valid Loss: 0.2287 Acc: 0.9107\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9807\n",
      "valid Loss: 0.2482 Acc: 0.9107\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0976 Acc: 0.9807\n",
      "valid Loss: 0.2878 Acc: 0.9107\n",
      "Training complete in 4m 7s\n",
      "Best valid Acc: 0.928571\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
