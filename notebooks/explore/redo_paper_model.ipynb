{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifiers based on paper\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rene/code/camelyon/src\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, vgg16, inception, inception_v3\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'src')\n",
    "print(src_dir)\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my functions:\n",
    "from tile_train_functions import*\n",
    "\n",
    "# Set it to use GPU1\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception\n",
    "(Deep Learning for Identifying Metastatic Breast Cancer arXiv:1606.05718v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-65494b69acc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inception'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "\n",
    "sz=224\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "###############################\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import pretrainedmodels.utils as utils\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "\n",
    "# transformations depending on the model\n",
    "# rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\n",
    "tf_img = utils.TransformImage(model) \n",
    "\n",
    "path_img = 'data/cat.jpg'\n",
    "\n",
    "input_img = load_img(path_img)\n",
    "input_tensor = tf_img(input_img)         # 3x400x225 -> 3x299x299 size may differ\n",
    "input_tensor = input_tensor.unsqueeze(0) # 3x299x299 -> 1x3x299x299\n",
    "input = torch.autograd.Variable(input_tensor,\n",
    "    requires_grad=False)\n",
    "\n",
    "output_logits = model(input) # 1x1000\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "# ????????\n",
    "model_arch = inception\n",
    "model_name = 'inception'\n",
    "\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                   num_epochs=epochs)\n",
    "torch.save(model_ft.state_dict(), os.path.join(save_path, model_name+'_full_dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# get the proper model architecture\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "# load the saved weights\n",
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, 'inception_full_dataset')))\n",
    "print('Validation: ', model_name[idx])\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "\n",
    "print('Test: ', model_name[idx])\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)\n",
    "results[model_name[idx]] = [valid_acc, test_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception v3\n",
    "(Detecting Cancer Metastases on Gigapixel Pathology Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/rene/Data/camelyon_out/tiles_224_100t/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-689f3808a04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/camelyon/src/tile_train_functions.py\u001b[0m in \u001b[0;36mmake_batch_gen\u001b[0;34m(PATH, batch_size, num_workers, valid_name, test_name, size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     image_datasets = {x: datasets.ImageFolder(os.path.join(PATH, x),\n\u001b[1;32m     48\u001b[0m                                               data_transforms[x])\n\u001b[0;32m---> 49\u001b[0;31m                       for x in list(data_transforms.keys())}\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
      "\u001b[0;32m/media/rene/Data/camelyon/src/tile_train_functions.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     image_datasets = {x: datasets.ImageFolder(os.path.join(PATH, x),\n\u001b[1;32m     48\u001b[0m                                               data_transforms[x])\n\u001b[0;32m---> 49\u001b[0;31m                       for x in list(data_transforms.keys())}\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m     97\u001b[0m     def __init__(self, root, transform=None, target_transform=None,\n\u001b[1;32m     98\u001b[0m                  loader=default_loader):\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/rene/Data/camelyon_out/tiles_224_100t/train'"
     ]
    }
   ],
   "source": [
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', size=299)\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "# ????????\n",
    "model_arch = inception_v3\n",
    "model_name = 'inception_v3'\n",
    "\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, epochs,\n",
    "                                dataloaders, dataset_sizes)\n",
    "torch.save(model_ft.state_dict(), os.path.join(save_path, model_name+'_full_dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/rene/Data/data/camelyon_out/tiles_224_100t'\n",
    "save_path = '/media/rene/Data/data/camelyon_out/tiles_224_100t/sample/models'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                            valid_name='valid', test_name ='test', size=299)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_arch = inception_v3\n",
    "model_name = 'inception_v3'\n",
    "\n",
    "# get the proper model architecture\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  inception_v3\n",
      "Loss: 0.1675 Acc: 0.9317\n",
      "Test:  inception_v3\n",
      "Loss: 0.3418 Acc: 0.8531\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3fc543513fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# load the saved weights\n",
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, 'inception_v3_full_dataset')))\n",
    "print('Validation: ', model_name)\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "\n",
    "print('Test: ', model_name)\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sensitivity/specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(all_labels, all_preds):\n",
    "    \"\"\"https://stackoverflow.com/questions/31324218\"\"\"\n",
    "    metrics = {}\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)\n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    metrics['TPR'] = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    metrics['TNR'] = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    metrics['PPV'] = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    metrics['NPV'] = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    metrics['FPR'] = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    metrics['FNR'] = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    metrics['FDR'] = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    metrics['ACC'] = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return metrics\n",
    "\n",
    "def get_metrics_bin(all_labels, all_preds):\n",
    "    metrics = {}\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    TP = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TN = cm[1][1]\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    metrics['TPR'] = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    metrics['TNR'] = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    metrics['PPV'] = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    metrics['NPV'] = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    metrics['FPR'] = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    metrics['FNR'] = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    metrics['FDR'] = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    metrics['ACC'] = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Validation sensitivity: 0.9317942107113559, specificity: 0.9315538141300355, Acc: 0.9316766467065868\n",
      "<class 'list'>\n",
      "Test sensitivity: 0.759115152574976, specificity: 0.9588501673557787, Acc: 0.8530678397777264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, 'inception_v3_full_dataset')))\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/rene/data/tiles_224_100t'\n",
    "save_path = '/home/rene/data/tiles_224_100t/models'\n",
    "num_workers = 4\n",
    "batch_size=16\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                            valid_name='valid', test_name ='test', size=224)\n",
    "\n",
    "model_arch = resnet34\n",
    "model_name = 'resnet34_scratch_no_samp_5'\n",
    "\n",
    "# get the proper model architecture\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sensitivity: 0.9131319986426875, specificity: 0.9443949611909912, Acc: 0.9278443113772455\n",
      "Test sensitivity: 0.7306666666666667, specificity: 0.9653986451276707, Acc: 0.8349617967122019\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_preds = get_preds(model_ft, dataloaders['valid'], dataset_sizes['valid'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['test'], dataset_sizes['test'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
